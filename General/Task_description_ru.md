# Self documenting API Gateway for ML serving in K8S

## Исходная формулировка задачи
A typical ingress implementation in k8s forwards incoming traffic to a particular application. An improved API Gateway would integrate Single Sign-On, automatic OpenAPI schema generation, request validation and response caching. The goal of the project is to develop such a Kubernetes operator to extend existing ingress implementations to API Gateway. 
The project should provide means to define API schema using Custom Resource Definitions in K8s directly and generate them from the source code following a set of conventions.

## Наброски, выдержки из переписок и брейн-шторма.

1. Есть persona Хади, есть Антон. Антон - разраб ML модели. Он сделал модель, которая делает очень классные штуки для вышки. Соответственно очень много людей, например Mr Хади - хотят эту модель поюзать. Но вот незадача - Антон хороший разраб, но он не знает как задеплоить модель на сервер, чтобы она там крутилась и работала. Для этого ему приходится попросить студента, который разрабатывает например FastAPI приложуху, которая использует его модель и предоставляет веб-апи для того, чтобы ей пользоваться из вне. А теперь Антон выкатывает v2 версию модели, где есть новые функции или старые изменились. Mr Хади видит, что что-то изменилось и вынужден идти к Антону и узнавать что там и как работает, что ему передавать зачем и почему, что на выходе.
Что делаем мы: даем Антону шаблон CRD для модели, например на tensorflow (т.е. у нас видимо будет наборчик шаблонов для разных фреймворков). Он заполняет этот шаблончик буквально: есть функция А, принимает Б, В, дает на выход Г, Д. Потом мы берем его модельку, на основе CRD от Антона генерим OpenAPI схему, запускаем модельку и пробрасываем к ней вот этот механизм использования через полученную схему. Соответственно потом приходит Хади, хочет поюзать модель. И ему не надо бежать опять к Антону - он просто вызывает какой-то типо /methods и ему выдается OpenAPI схема с описанием методов, которое заполнил Антон. 
Если же мы не знаем фреймворка, на котором написана нейронка, то мы будем парсить source code и искать там методы.
Дефолтные фичи, которые должен делать GatewayAPI: SSO и всякое - например если мы хотим дать студентам доступ к методам нейронки /get_grades, а для преподов - /set_grades. Тогда нам нужно уметь аутентифицировать челов и вот тут фичи с SSO вступят в силу. Кэширование думаю тоже понятно - на любой запрос по-сути будет.

2. Есть разработчик ML модели, который её разработал и хочет сделать доступной для внешних сервисов. Для этого ему нужно её где-то развернуть. Но он этого не умеет делать (например) и просит помощи у другого разработчика, который на основе функций модели делает некое web-api приложение, которое запускает модель и предоставляет к ней доступ через например http запросы вида /do_smth. Но потом разработчик меняет какие-то функции или добавляет новые. И теперь ему надо снова менять веб сервер, а также юзерам - ждать документацию, чтобы понять что и как изменилось.
Что делаем мы и какая будет новая User Story: разработчик написал ML модель, хочет её задеплоить. Он приходит в наш сервис, мы даем ему шаблоны CRD для известных нам ML фреймворков (например tensorflow) и просим его описать какие он хочет функции ML сделать доступными, что они принимают и что отдают. Если же фреймворк нам неизвестен, то мы будем парсить исходный код и пытаться сами собрать CRD. Затем разработчик отдает сервису эту CRD, на её основе мы создаем веб-апи с указанными методами, который также поднимает модель и позволяет с ней общаться. А также мы генерируем OpenAPI схему на этой основе и например через запрос вида /methods он сможет получить поддерживаемые методы и их входные и выходные параметры. То есть в этом и будут заключаться Self-Documenting и OpenAPI schema generation фичи.
Ну и основные фичи Gateway API как такового типа Response Caching - понятно что будет делать, SSO и все связанное с авторизацией - тоже и будет использоваться например чтобы к некоторому функционалу ограничить доступ группам пользователей.

3. Разработчик ML-модели хочет развернуть и опубликовать для использования свой сервис. Для этого у него изначально есть его модель(-и) (e.g. как скомпилированный в бинарный файл Python-класс из его фреймворка, например TensorFlow, Scikit-learn, Pytorch etc.), а также web-api сервис, который может эту модель запускать. Мы считаем, что сервис не просто предоставляет API-методов для запуска моделей, а решает некую комплексную задачу, которая скрывает под собой как запуск модели(-ей) с различными входными данными, так и различную промежуточную обработку (которая включает в себя вообще что угодно, от обработки данных с помощью numpy, до запросов в интернет с целью какие-то данные собрать). Таким образом под условным /api/v1/do_smh скрывается большая функция, включающая в себя работу с ML-моделью. Поскольку существующие решения для быстрого сёрвинга моделей в контейнерах обычно решают задачу, в которой одной модели в соответствие ставится одна функция (например, [KServe](https://github.com/kserve/kserve?tab=readme-ov-file) или Seldon-core+[Ambassador](https://docs.seldon.io/projects/seldon-core/en/latest/ingress/ambassador.html) на его основе), то они не подойдут нашему ML-разработчику, и он всё равно будет вынужден сам написать web-api сервис, используя все нужные ему библиотеки + его ML-фреймворк + api-фреймворк (e.g. [FastAPI](https://fastapi.tiangolo.com/tutorial/first-steps/), Flask, или что-то более специализированное для его задачи, например [MLRun](https://docs.mlrun.org/en/latest/index.html)). Теперь разработчик публикует образ, включающий в себя выше упомянутое, и деплоит его в кластер, заполнив CRD с информацией о доступных функциях (но не моделях). На его основе мы генерируем и публикуем OpenAPI схему, но не создаём своего web-api, а только переадресуем запросы к web-api, написанному разработчиком. Если же CRD не содержит информации о функциях, то мы пытаемся найти функции самостоятельно в исходном коде web-api разработчика.

4. В задаче API Gateway != k8s Gateway API. На k8s Gateway API можно смотреть, можно использовать на базе nginx-gateway-fabric или другого OSS сертифицированного CNCF. Нужен не только роутинг к сервисам. Нужна генерерация OpenAPIv3 схемы на лету из метаданных, описания как ресурса CRD или кода (с помощью доп библиотеки) ML сервиса. ML сервис - это решение задачи сервинга (serving) моделей. Считайте, что все такие сервисы должны иметь API, построенный по общим правилам (входы, выходы, типы данных, авторизацмя и т п). А разработчик модели пишет только модель, но не сервис. Ценность в том, что создаваемая gateway собирает и публикует API в едином виде для размещаемых сервисов, сохраняя совместимость с нестандартными сервисами. Так что DevOps-ы при развертывании уже не участвуют в определении и развертывании API.

5. ML разработчик решает какую-то прикладную задачу. А значит чистым ml фреймворком ему не обойтись. Разные методы одного ml сервиса могут делать разные истории или разные шаги истории, которым нужна одна и та же модель.

6. У вас может быть библиотека сервинга, которая оборачивает модель или код inference в сервис и анализирует этот код.

## Детальное описание задачи
Разрабатываемый Self Documenting API Gateway представляет собой платформу для развертывания, публикации и управления моделями машинного обучения в Kubernetes. Состоит из ресурсов K8S.

### Рассмотрение кандидатов в фичи
1. Маршрутизация запросов. Самая стандартная функция базового K8S [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/). Реверс-прокси направляет внешний трафик к требуемым K8S-сервисам.
Примеры: Существуют примеры [Gateway API](https://gateway-api.sigs.k8s.io/implementations/), самые известные HaProxy, Istio, Ambassador Ingress. Также на их основе, [Seldon Core](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/github-readme.html) умеет публиковать ML-модели сразу с API маршрутами.
2. Балансировка нагрузки. Вообще Kubernetes осуществляет её при помощи K8S-[сервисов](https://kubernetes.io/docs/concepts/services-networking/service/), но не Ingress. Как правило настраивается весами.
Примеры: [Istio](https://istio.io/latest/docs/concepts/traffic-management/). Ambassador в [Seldon Core](https://docs.seldon.io/projects/seldon-core/en/latest/ingress/ambassador.html).
3. Аудит, логирование. Расширение логов базового nginx. В перспективе интеграция с инструментами хранения и ротации логов, таких как ELK Stack, Fluentd.
Примеры: [HaProxy](https://www.haproxy.com/blog/logging-with-the-haproxy-kubernetes-ingress-controller)
4. SSO. Авторизация. Нестандартная функция Ingress, добавляемая Gateway API. Позволяет регулировать доступ к API, используя инструменты аутентификации, например OAuth, JWT.
Примеры: [HaProxy](https://www.getambassador.io/docs/edge-stack/latest/howtos/ext-filters), [Istio](https://istio.io/latest/docs/tasks/security/).
5. Валидация запросов. Непопулярная функция, осуществляющая верификацию запросов к API в соответствии с OpenAPI-схемой. Очень удачно сочетается с функцией автогенерации схемы.
Примеры: [Yandex API Gateway](https://yandex.cloud/ru/docs/api-gateway/concepts/extensions/validator?utm_referrer=https%3A%2F%2Fwww.google.com%2F).
6. Кэширование ответов. Уже реализована в простой форме в nginx.
Примеры: [K8S Ingress](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#server-snippet)
7. Модульное развертывание моделей. Поддержка развертывания различных моделей машинного обучения (ML), написанных на разных языках программирования и использующих различные фреймворки (TensorFlow, PyTorch, Scikit-learn и т.д.).
Примеры: [Seldon Core](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/github-readme.html)
8. Контейнеризация. Возможность упаковки ML-моделей в контейнеры с использованием Docker. Генерирация класса с функциями ML. Настраивается на основе CRD.
Примеры: [Language wrapper](https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html), [KServe](https://github.com/kserve/kserve).
9. Развёртывание сервиса. Автоматизация развертывания моделей из специальных хранилищ и систем контроля версий в Kubernetes-кластерах на основе стандартных Kubernetes объектов (Deployments, Services, Pods).
Примеры: [Deployment](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/overview.html#seldondeployment-crd).
10. Автодокументирование моделей. Генерации OpenAPI спецификаций для моделей путём описания моделей при деплое из полей ресурса, либо путём чтения исходного кода (описания класса) контейнезированного приложения.
Примеры: [OpenAPI](https://docs.seldon.io/projects/seldon-core/en/latest/reference/apis/openapi.html), [Metadata](https://docs.seldon.io/projects/seldon-core/en/latest/reference/apis/metadata.html).