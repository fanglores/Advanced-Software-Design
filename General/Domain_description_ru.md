# Self documenting API Gateway for ML serving in K8S

## Детальное описание предметной области

### Облачный хостинг
Любое сетевое приложение или сервис, перед тем, как станет доступно для конечного пользователя, должно быть развёрнуто в некоторой инфраструктуре. Реализация API Gateway в общем относится к большой задаче и предметной области хостинга облачных сервисов.
Эта задача охватывает широкий спектр технологий, направленных на предоставление вычислительных ресурсов, хранилищ и сетевых услуг по запросу через сеть (это может быть как Интернет, так и локальные сети внутри компаний). Ключевыми элементами облачной инфраструктуры являются виртуализация, автоматизация процессов, балансировка нагрузки и обеспечение высокой доступности. Это позволяет разработчикам инфраструктуры динамически масштабировать свои приложения и снижать затраты на эксплуатацию физических серверов.
Иначе говоря: собрать (или арендовать) в каком-нибудь датацентре кластер из нескольких серверов будет выгоднее по времени и ресурсам, чем выделять по физическому серверу на каждую решаемую бизнес-задачу или сервис. Это достигается благодаря набору технологий, который позволяет свести развёртывание и хостинг приложений к набору простых абстраций.
Использование такой облачной инфраструктуры позволяет разделить задачи обеспечения работоспособности "железной" и "программной" части серверов. Именно про "программную" часть дальше и пойдёт речь.

### Kubernetes
Одной из центральных технологий в этой области является Kubernetes (сокращенно K8S) — система для оркестрации контейнеризированных приложений. K8S автоматизирует развертывание, управление и масштабирование контейнеров, что позволяет легко управлять сложными распределенными системами. Важным аспектом работы Kubernetes является его способность управлять ресурсами в виде кластеров, состоящих из множества узлов (виртуальных или физических машин). Разумеется, существует множество и других больших технологий и "фреймворков" для построения облачной инфраструктуры, общая организация которых похожа, но довольно косвенно относится к нашей задаче.
Система K8S по-сути своей предоставляет собой совокупность из нескольких программ, которые управляются с помощью API. Различные механизмы и компоненты K8S (e.g. Ingress, Service, Deployment, Pod, Job) - это программные абстрации, иначе называемые "Ресурсами", у которых есть свои экземпляры, состояния, параметры и конфигурации. Они же позволяют удобно настраивать, модифицировать K8S, а также налаживать интеграцию с другими большими инфраструктурными системами (e.g. AD, Vault, Monitoring, SOC).

### Custome Resource Definition
Ресурс можно определить с помощью CRD, и даже написать свой обработчик, называемый "Оператором", для него. Пример:
``` yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: myresources.example.com
spec:
  group: example.com                    # Группа API для CRD
  versions:
    - name: v1                          # Версия API
      served: true                      # Делать ресурс доступным
      storage: true                     # Использовать эту версию для хранения
      schema:                           # Определение схемы
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              properties:
                name:
                  type: string
                replicas:
                  type: integer
  scope: Namespaced                     # Ресурс относится к namespace (можно "Cluster" для кластерного уровня)
  names:
    plural: myresources                 # Множественное число ресурса
    singular: myresource                # Единственное число ресурса
    kind: MyResource                    # Название типа ресурса
    shortNames:
      - mr                              # Краткое имя для команды kubectl
```
После этого в Kubernetes можно будет создать экземпляры этого нового ресурса, заполнив определенные в CRD поля:
```yaml
apiVersion: example.com/v1
kind: MyResource
metadata:
  name: myresource-sample
spec:
  name: "My Custom Resource"
  replicas: 3
```

### Маршрутизация сетевого трафика
Одной из ключевых задач при организации облачных кластеров является маршрутизация сетевого трафика. В K8S эта задача решается с помощью встроенных [механизмов](https://kubernetes.io/docs/concepts/services-networking/), таких как Ingress-контроллеры и сервисы, которые обеспечивают маршрутизацию внешних запросов к нужным контейнерам внутри кластера. Правильная маршрутизация и балансировка трафика жизненно важны для обеспечения высокой производительности и доступности облачных приложений. Это также включает такие задачи, как:
* Балансировка нагрузки между различными экземплярами приложений для оптимального распределения запросов. Эту задачу решают ресурсы, тот же Ingress, LoadBalancer, Service.
* Трафик-менеджмент для управления маршрутизацией на основе правил и политик, таких как фильтрация запросов, проверка доступности сервисов и ограничение доступа. В контексте этой задачи, в частности, применяют SSO и кэширование. Эту задачу решают с помощью ресурсов, вроде Ingress, NetworkPolicy. Также применяют и ПО, разворачиваемое прямо внутри кластера: Redis/Firefly, External-Auth-Server.
* Обеспечение безопасности сети через применение шифрования трафика и управления межсервисными коммуникациями. И снова Ingress, NetworkPolicy.

K8S Ingress - самый базовый ресурс для маршрутизации трафика извне кластера к K8S-сервисам внутри него. Этот ресурс основан на базовом образе nginx и позволяет решить простую задачу: связать некий путь с неким сервисом. Осуществляет как L4 (TCP/UDP) так и L7 (HTTP) маршрутизацию.
Несложно заметить, что решаемых задач для маршрутизации трафика очень много, но все они предельно стандартные. Поэтому для K8S существует много решений, разработанных третьими лицами, для решения перечисленных задач, одна из которых Gateway API - большой ресурс K8S, призванный не заменить, но очень качественно дополнить стандартный набор сетевых ресурсов системы. Каждая [реализация](https://gateway-api.sigs.k8s.io/implementations/) имеет свои плюсы и минусы, набор функций, параметры и конфигурации. Поэтому желаемую реализацию Gateway API выбирают исходя из задачи, которую решает Kubernetes-кластер: простой сайт, сервис со сложным API, обменник файлами, стриминговый сервис и т.д.

### ML-Serving
Как выяснилось, Self Documenting API Gateway будет использован для решения задачи обслуживания (сёрвинга) моделей машинного обучения.
Задача сёрвинга моделей машинного обучения (ML serving) заключается в предоставлении готовой обученной модели (например собранный в бинарный файл Python-класс) для обработки запросов в реальном времени или пакетном режиме. Это финальный этап ML-пайплайна, на котором модель интегрируется в приложение для решения бизнес-задач.
Это критически важный этап, где обученная модель разворачивается в производственной среде и начинает принимать запросы от внешних систем для генерации предсказаний. Основные задачи этого слоя:
* Интеграция с API: Модель оборачивается в интерфейс, который позволяет внешним системам отправлять запросы и получать предсказания. Этим интерфейсом может быть:
  * Python-приложение, предоставляющее API (FastAPI, Flask) и библиотекой (Torch, TensorFlow, LLM) для работы с моделью. Этот способ самый сложный в реализации, но сохраняет все функции для работы разработки моделей (e.g. дообучения, фильтрация данных).
  * Приложение, предоставляюее API и инструменты сёрвинга ML-моделей (MLRun). Этот способ проще и в добавок позволяет работать с широким спектром моделей, в том числе с других языков, но лишен некоторых функций для разработки моделей.
  * Внешний инструмент сёрвинга ML-моделей (KServe, Seldon Core, BentoML). Такие инструменты имеют широкую интеграцию с облачными инструментами (e.g. тем же K8S Gateway API, или репозиториями для хранения и версионирования моделей) и позволяют ускорить развёртывание моделей. Чаще всего они предполагают только запуск моделей, стараясь соответствовать принципу "Do one thing and do it right", предлагая API для других сервисов, которые могут комбинировать его вызовы с другими функциями.
* Масштабируемость: Модели должны эффективно обрабатывать как одиночные запросы, так и высокие объемы трафика, для чего используются инструменты автоматического масштабирования.
* Низкая задержка: Важно минимизировать время ответа модели, чтобы обеспечить быструю обработку запросов в реальном времени.
* Обновление моделей: Регулярная замена устаревших моделей на новые версии без прерывания работы системы.

Исходя из двух предыдущих параграфов, ML-serving - почти эталонная задача для реализации в Kubernetes. И API Gateway, совместно с упомянутыми типовыми инструментами, помог бы обеспечить доступ к API ML-моделей и сервисов, которые их используют.
Описанный подход на основе Kubernetes позволяет реализовать облако с широким спектром функций и API-вызов, а граммотно выстроенный в команде ML-Ops позволит ускорить процессы разработки самих моделей, а также ML-сервисов. Но для внутренних и внешних пользователей API ML-сервисов требуется его описание для своевременного перехода на новые версии.

### OpenAPI
OpenAPI — это спецификация, которая позволяет описывать RESTful API в машиночитаемом формате. Она стандартизирует способ представления API, предоставляя разработчикам и пользователям API унифицированный способ документирования, взаимодействия и генерации кода для клиентских и серверных приложений.
Основные аспекты OpenAPI:
1. Формат описания API: OpenAPI предоставляет спецификацию в формате YAML или JSON, которая описывает структуру API: доступные эндпоинты, методы HTTP (GET, POST, PUT, DELETE и др.), типы запросов и ответов, параметры, заголовки и коды ответов. Это позволяет создать стандартизированное и детализированное описание интерфейсов API.
2. Машиночитаемость: Так как OpenAPI представлен в виде структуры данных, разработчики могут легко автоматизировать генерацию клиентского и серверного кода, тестов, документации и инструментов для валидации API. Например, можно использовать инструменты для генерации клиентских библиотек на разных языках программирования.
3. Документация: Одной из ключевых целей OpenAPI является упрощение документирования API. Описание API включает не только информацию о доступных ресурсах, но и примеры запросов и ответов, что делает документацию понятной как для разработчиков, так и для пользователей.
4. Интерактивное тестирование: С OpenAPI можно автоматически создавать интерфейсы для интерактивного тестирования API. Такие инструменты, как Swagger UI или ReDoc, позволяют пользователям отправлять запросы к API и видеть результаты прямо в браузере. Это помогает быстро понять, как работает API, и протестировать его функциональность без написания кода.

В спецификации OpenAPI есть несколько ключевых разделов:
1. Info: Содержит общую информацию об API, такую как название, описание, версия, контактная информация.
2. Paths: Описывает все доступные маршруты (эндпоинты) API и связанные с ними HTTP-методы (например, GET /users, POST /users/{id}).
3. Components: Содержит переиспользуемые компоненты, такие как схемы данных, определения типов запросов/ответов, параметры и коды ошибок.
4. Security: Описывает механизмы авторизации, такие как OAuth2, JWT, API-ключи и др.
5. Servers: Описывает базовые URL для доступа к API.
6. Tags: Используются для группировки и организации методов API.
Пример:
```yaml
openapi: 3.0.0
info:
  title: Simple API
  description: A simple API to demonstrate OpenAPI
  version: 1.0.0
paths:
  /users:
    get:
      summary: Get all users
      responses:
        '200':
          description: A list of users
          content:
            application/json:
              schema:
                type: array
                items:
                  type: string
```
Часто предоставляют схему OpenAPI через специальный URL-эндпоинт API (/openapi.json или /swagger.json). Этот эндпоинт обычно возвращает OpenAPI-схему в формате JSON. Он может быть связан с версией (/v1/openapi.json).
Многие API-разработчики внедряют интерактивную документацию, например Swagger UI или ReDoc, где пользователи могут взаимодействовать с API и просмотреть OpenAPI-схему. Например, на странице с документацией API (e.g https://api.example.com/docs) может быть встроен Swagger UI. Пользователь может увидеть не только описание API, но и загрузить схему, используя интерфейс Swagger UI (в разделе "Export" или "Download").
Специализированные платформы для управления API, такие как Kong, Apigee, AWS API Gateway, или Azure API Management, позволяют автоматизировать публикацию OpenAPI-схемы. Эти сервисы могут автоматически генерировать и предоставлять схему через удобные интерфейсы или интеграции.